import asyncio
import json
from openai import AsyncOpenAI
from mcp.client.session import ClientSession
from mcp.client.stdio import stdio_client, StdioServerParameters

# åˆå§‹åŒ– API å®¢æˆ·ç«¯ (ä½¿ç”¨ OpenAI å…¼å®¹æ¨¡å¼)
API_KEY = "sk-e3bb89eb98484d31ad2ec9ae2784ac83" 

llm_client = AsyncOpenAI(
    api_key=API_KEY,
    base_url="https://api.deepseek.com"
)

async def run_deepcontext_agent():
    print("ğŸš€ æ­£åœ¨å¯åŠ¨ DeepContext çœŸå®æ™ºèƒ½ Agent å®¢æˆ·ç«¯...\n")

    server_params = StdioServerParameters(command="python", args=["server.py"])

    async with stdio_client(server_params) as (read_stream, write_stream):
        async with ClientSession(read_stream, write_stream) as session:
            await session.initialize()
            print("âœ… æˆåŠŸè¿æ¥åˆ°æœ¬åœ° MCP Serverï¼")
            
            # 1. è·å– MCP Server æä¾›çš„å·¥å…·ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸º å¤§æ¨¡å‹ èƒ½æ‡‚çš„ JSON Schema æ ¼å¼
            mcp_tools = await session.list_tools()
            qwen_tools = []
            for t in mcp_tools.tools:
                qwen_tools.append({
                    "type": "function",
                    "function": {
                        "name": t.name,
                        "description": t.description,
                        "parameters": t.inputSchema # MCP è‡ªåŠ¨ç”Ÿæˆçš„æ ‡å‡† JSON Schema
                    }
                })
            
            # 2. å‡†å¤‡å¯¹è¯å†å² (Memory)
            user_query = "å¸®æˆ‘çœ‹çœ‹å½“å‰ '.' ç›®å½•ä¸‹æœ‰å“ªäº› md ç¬”è®°æ–‡ä»¶ï¼Ÿ"
            print(f"ğŸ§‘â€ğŸ’» [ç”¨æˆ·æé—®]: {user_query}\n")
            
            messages = [{"role": "user", "content": user_query}]
            
            # =====================================================================
            # 3. ç¬¬ä¸€æ¬¡è¯·æ±‚å¤§æ¨¡å‹ (å¤§è„‘å¼€å§‹æ¨ç†ä¸è·¯ç”±)
            # =====================================================================
            print("ğŸ§  [å¤§æ¨¡å‹æ€è€ƒä¸­...]")
            response = await llm_client.chat.completions.create(
                model="deepseek-chat", 
                messages=messages,
                tools=qwen_tools # æŠŠå·¥å…·è¯´æ˜ä¹¦â€œå–‚â€ç»™æ¨¡å‹
            )
            
            assistant_message = response.choices[0].message
            
            # åˆ¤æ–­å¤§æ¨¡å‹æ˜¯å¦å†³å®šè°ƒç”¨å·¥å…·
            if assistant_message.tool_calls:
                # =====================================================================
                # 4. æˆªè·å·¥å…·è°ƒç”¨æŒ‡ä»¤ï¼Œå¹¶åœ¨æœ¬åœ°æ‰§è¡Œ (Action)
                # =====================================================================
                tool_call = assistant_message.tool_calls[0]
                func_name = tool_call.function.name
                # è§£æå¤§æ¨¡å‹ç”Ÿæˆçš„å‚æ•° JSON
                func_args = json.loads(tool_call.function.arguments) 
                
                print(f"âš¡ [è§¦å‘æ‰§è¡Œ]: Qwen å†³å®šè°ƒç”¨å·¥å…· `{func_name}`, æå–åˆ°çš„å‚æ•°: {func_args}")
                
                # çœŸæ­£å‘æœ¬åœ°çš„ MCP Server å‘èµ·è°ƒç”¨è¯·æ±‚
                mcp_result = await session.call_tool(func_name, arguments=func_args)
                tool_result_text = mcp_result.content[0].text
                print(f"ğŸ“¦ [æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿè¿”å›]:\n{tool_result_text}\n")
                
                # =====================================================================
                # 5. å°†æ‰§è¡Œç»“æœæ‹¼æ¥åˆ°ä¸Šä¸‹æ–‡ä¸­ï¼Œå‘èµ·ç¬¬äºŒæ¬¡è¯·æ±‚ (Observation & æ€»ç»“)
                # =====================================================================
                # é‡ç‚¹ï¼šå¿…é¡»æŠŠå¤§æ¨¡å‹åˆšæ‰çš„â€œè°ƒç”¨åŠ¨ä½œâ€ä¹ŸåŠ è¿›å†å²è®°å½•ï¼Œç»´æŒå¯¹è¯é“¾çš„å®Œæ•´æ€§
                messages.append(assistant_message) 
                # æŠŠæœ¬åœ°å·¥å…·æ‰§è¡Œçš„ç»“æœå‘Šè¯‰å¤§æ¨¡å‹
                messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "name": func_name,
                    "content": tool_result_text
                })
                
                print("ğŸ§  [å¤§æ¨¡å‹é˜…è¯»æœ¬åœ°æ•°æ®å¹¶æ€»ç»“ä¸­...]")
                final_response = await llm_client.chat.completions.create(
                    model="deepseek-chat",
                    messages=messages
                )
                
                print(f"ğŸ¤– [Agent æœ€ç»ˆå›ç­”]:\n{final_response.choices[0].message.content}")
                
            else:
                # å¦‚æœå¤§æ¨¡å‹è®¤ä¸ºä¸éœ€è¦è°ƒç”¨å·¥å…·ï¼Œç›´æ¥è¾“å‡ºäº†æ™®é€šæ–‡æœ¬
                print(f"ğŸ¤– [Agent ç›´æ¥å›ç­”]:\n{assistant_message.content}")

if __name__ == "__main__":
    asyncio.run(run_deepcontext_agent())